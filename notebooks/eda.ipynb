{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df017282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 'TL_1. ì§ˆì˜ì‘ë‹µ ë°ì´í„°.zip' â†’ 'TL_1. ì§ˆì˜ì‘ë‹µ ë°ì´í„°/' í•´ì œ ì™„ë£Œ\n",
      "âœ… 'TL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ë²”ì£„.zip' â†’ 'TL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ë²”ì£„/' í•´ì œ ì™„ë£Œ\n",
      "âœ… 'TL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ë¹„ë‚œí˜ì˜¤ì°¨ë³„.zip' â†’ 'TL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ë¹„ë‚œí˜ì˜¤ì°¨ë³„/' í•´ì œ ì™„ë£Œ\n",
      "âœ… 'TL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ì„ ì •.zip' â†’ 'TL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ì„ ì •/' í•´ì œ ì™„ë£Œ\n",
      "âœ… 'TL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ìŠ¤íŒ¸ë°ê´‘ê³ .zip' â†’ 'TL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ìŠ¤íŒ¸ë°ê´‘ê³ /' í•´ì œ ì™„ë£Œ\n",
      "âœ… 'TL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ìš•ì„¤.zip' â†’ 'TL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ìš•ì„¤/' í•´ì œ ì™„ë£Œ\n",
      "âœ… 'TL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_í­ë ¥.zip' â†’ 'TL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_í­ë ¥/' í•´ì œ ì™„ë£Œ\n",
      "âœ… 'TL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_í—ˆìœ„ì •ë³´ë°ë£¨ë¨¸.zip' â†’ 'TL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_í—ˆìœ„ì •ë³´ë°ë£¨ë¨¸/' í•´ì œ ì™„ë£Œ\n",
      "âœ… 'VL_1. ë§ë­‰ì¹˜ ë°ì´í„°.zip' â†’ 'VL_1. ë§ë­‰ì¹˜ ë°ì´í„°/' í•´ì œ ì™„ë£Œ\n",
      "âœ… 'VL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ë²”ì£„.zip' â†’ 'VL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ë²”ì£„/' í•´ì œ ì™„ë£Œ\n",
      "âœ… 'VL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ë¹„ë‚œí˜ì˜¤ì°¨ë³„.zip' â†’ 'VL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ë¹„ë‚œí˜ì˜¤ì°¨ë³„/' í•´ì œ ì™„ë£Œ\n",
      "âœ… 'VL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ì„ ì •.zip' â†’ 'VL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ì„ ì •/' í•´ì œ ì™„ë£Œ\n",
      "âœ… 'VL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ìŠ¤íŒ¸ë°ê´‘ê³ .zip' â†’ 'VL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ìŠ¤íŒ¸ë°ê´‘ê³ /' í•´ì œ ì™„ë£Œ\n",
      "âœ… 'VL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ìš•ì„¤.zip' â†’ 'VL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_ìš•ì„¤/' í•´ì œ ì™„ë£Œ\n",
      "âœ… 'VL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_í­ë ¥.zip' â†’ 'VL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_í­ë ¥/' í•´ì œ ì™„ë£Œ\n",
      "âœ… 'VL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_í—ˆìœ„ì •ë³´ë°ë£¨ë¨¸.zip' â†’ 'VL_2. ìœ í•´ì§ˆì˜ ë°ì´í„°_í—ˆìœ„ì •ë³´ë°ë£¨ë¨¸/' í•´ì œ ì™„ë£Œ\n",
      "âœ… ëª¨ë“  zip í•´ì œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def unzip_into_subfolders(base_dir):\n",
    "    \"\"\"\n",
    "    base_dir ì•ˆì˜ ëª¨ë“  zip íŒŒì¼ì„ ê°™ì€ ì´ë¦„ì˜ í´ë”ë¡œ í’€ê¸°.\n",
    "    ì˜ˆ: base_dir/ìš•ì„¤.zip â†’ base_dir/ìš•ì„¤/...\n",
    "    \"\"\"\n",
    "    for fname in os.listdir(base_dir):\n",
    "        if not fname.endswith(\".zip\"):\n",
    "            continue\n",
    "\n",
    "        zip_path = os.path.join(base_dir, fname)\n",
    "        folder_name = fname.replace(\".zip\", \"\").strip()\n",
    "        target_path = os.path.join(base_dir, folder_name)\n",
    "        os.makedirs(target_path, exist_ok=True)\n",
    "\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(target_path)\n",
    "            print(f\"âœ… '{fname}' â†’ '{folder_name}/' í•´ì œ ì™„ë£Œ\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unzip_into_subfolders(r\"C:\\Users\\MSI\\Desktop\\SpamGuard-MLOps\\data\\train\\02.ë¼ë²¨ë§ë°ì´í„°\")\n",
    "\n",
    "    unzip_into_subfolders(r\"C:\\Users\\MSI\\Desktop\\SpamGuard-MLOps\\data\\test\\02.ë¼ë²¨ë§ë°ì´í„°\")\n",
    "\n",
    "    print(\"âœ… ëª¨ë“  zip í•´ì œ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84185924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_normal_from_corpus(json_path, limit=None):\n",
    "    rows = []\n",
    "    with open(json_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        data = json.load(f)[\"data\"]\n",
    "\n",
    "    for i, entry in enumerate(data):\n",
    "        for label in entry.get(\"labels\", []):\n",
    "            response = label.get(\"response\", \"\").strip()\n",
    "            if response:\n",
    "                rows.append({\"text\": response, \"label\": \"ì •ìƒ\"})\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df = load_normal_from_corpus(r\"C:\\Users\\MSI\\Desktop\\SpamGuard-MLOps\\data\\test\\02.ë¼ë²¨ë§ë°ì´í„°\\VL_1. ë§ë­‰ì¹˜ ë°ì´í„°\\validation(yes,no).json\")\n",
    "df.to_csv(\"data/normal_corpus1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c41da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_normal_from_corpus(json_path, limit=None):\n",
    "    rows = []\n",
    "    with open(json_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        data = json.load(f)[\"data\"]\n",
    "\n",
    "    for i, entry in enumerate(data):\n",
    "        for label in entry.get(\"labels\", []):\n",
    "            response = label.get(\"response\", \"\").strip()\n",
    "            if response:\n",
    "                rows.append({\"text\": response, \"label\": \"ì •ìƒ\"})\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df = load_normal_from_corpus(r\"C:\\Users\\MSI\\Desktop\\SpamGuard-MLOps\\data\\test\\02.ë¼ë²¨ë§ë°ì´í„°\\VL_1. ë§ë­‰ì¹˜ ë°ì´í„°\\validation(ì˜ë¬¸ì‚¬).json\")\n",
    "df.to_csv(\"data/normal_corpus2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a27b5a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_normal_from_corpus(json_path, limit=None):\n",
    "    rows = []\n",
    "    with open(json_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        data = json.load(f)[\"data\"]\n",
    "\n",
    "    for i, entry in enumerate(data):\n",
    "        for label in entry.get(\"labels\", []):\n",
    "            response = label.get(\"response\", \"\").strip()\n",
    "            if response:\n",
    "                rows.append({\"text\": response, \"label\": \"ì •ìƒ\"})\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df = load_normal_from_corpus(r\"C:\\Users\\MSI\\Desktop\\SpamGuard-MLOps\\data\\train\\TL_1. ì§ˆì˜ì‘ë‹µ ë°ì´í„°\\training(yes,no).json\")\n",
    "df.to_csv(\"data/train_normal_corpus1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "058f72bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_normal_from_corpus(json_path, limit=None):\n",
    "    rows = []\n",
    "    with open(json_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        data = json.load(f)[\"data\"]\n",
    "\n",
    "    for i, entry in enumerate(data):\n",
    "        for label in entry.get(\"labels\", []):\n",
    "            response = label.get(\"response\", \"\").strip()\n",
    "            if response:\n",
    "                rows.append({\"text\": response, \"label\": \"ì •ìƒ\"})\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df = load_normal_from_corpus(r\"C:\\Users\\MSI\\Desktop\\SpamGuard-MLOps\\data\\train\\TL_1. ì§ˆì˜ì‘ë‹µ ë°ì´í„°\\training(ì˜ë¬¸ì‚¬).json\")\n",
    "df.to_csv(\"data/train_normal_corpus2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8c8a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "LABEL_MAP = {\n",
    "    1: \"ë¹„ë‚œí˜ì˜¤ì°¨ë³„\",\n",
    "    2: \"ì„ ì •\",\n",
    "    3: \"ìŠ¤íŒ¸ë°ê´‘ê³ \",\n",
    "    4: \"ìš•ì„¤\",\n",
    "    5: \"í­ë ¥\",\n",
    "    6: \"í—ˆìœ„ì •ë³´ë°ë£¨ë¨¸\",\n",
    "    7: \"ë²”ì£„\"\n",
    "}\n",
    "\n",
    "def collect_labeled_data(base_dir):\n",
    "    rows = []\n",
    "    for category in os.listdir(base_dir):\n",
    "        cat_path = os.path.join(base_dir, category)\n",
    "        if not os.path.isdir(cat_path): continue\n",
    "        for fname in os.listdir(cat_path):\n",
    "            if not fname.endswith(\".json\"): continue\n",
    "            try:\n",
    "                with open(os.path.join(cat_path, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)[\"data\"][0]\n",
    "                    text = data[\"instruct_text\"].strip()\n",
    "                    level1 = data[\"labels\"][0][\"level1_type\"]\n",
    "                    label = LABEL_MAP.get(level1, \"ê¸°íƒ€\")\n",
    "                    rows.append({\"text\": text, \"label\": label})\n",
    "            except Exception as e:\n",
    "                print(f\"[ì—ëŸ¬: {fname}] {e}\")\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ì‹¤í–‰ ì˜ˆì‹œ\n",
    "train_df = collect_labeled_data(r\"C:\\Users\\MSI\\Desktop\\SpamGuard-MLOps\\data\\train\\02.ë¼ë²¨ë§ë°ì´í„°\")\n",
    "test_df = collect_labeled_data(r\"C:\\Users\\MSI\\Desktop\\SpamGuard-MLOps\\data\\test\\02.ë¼ë²¨ë§ë°ì´í„°\")\n",
    "\n",
    "train_df.to_csv(\"data/harmful_train.csv\", index=False)\n",
    "test_df.to_csv(\"data/harmful_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76644267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë³‘í•© ì™„ë£Œ: ì´ 2112ê°œ ë¬¸ì¥ â†’ data/merged_test.csv ì €ì¥ë¨\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ê° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "harmful = pd.read_csv(\"data/harmful_test.csv\")\n",
    "normal1 = pd.read_csv(\"data/normal_corpus1.csv\")\n",
    "normal2 = pd.read_csv(\"data/normal_corpus2.csv\")\n",
    "\n",
    "# ìœ í•´ ë¬¸ì¥ ìˆ˜\n",
    "n_harmful = len(harmful)\n",
    "\n",
    "# ì •ìƒì€ ë°˜ë°˜ ìƒ˜í”Œë§ (ì´í•©ì´ ìœ í•´ì™€ ë™ì¼í•˜ê²Œ)\n",
    "n_each = n_harmful // 2\n",
    "normal1_sampled = normal1.sample(n=n_each, random_state=42)\n",
    "normal2_sampled = normal2.sample(n=n_harmful - n_each, random_state=42)  # odd num ëŒ€ì‘\n",
    "\n",
    "# ë³‘í•©\n",
    "merged = pd.concat([harmful, normal1_sampled, normal2_sampled], ignore_index=True)\n",
    "\n",
    "# ì…”í”Œ (ëª¨ë¸ í•™ìŠµ ì•ˆì •í™”ë¥¼ ìœ„í•´)\n",
    "merged = merged.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# ì €ì¥\n",
    "merged.to_csv(\"data/merged_test.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… ë³‘í•© ì™„ë£Œ: ì´ {len(merged)}ê°œ ë¬¸ì¥ â†’ data/merged_test.csv ì €ì¥ë¨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c2404b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë³‘í•© ì™„ë£Œ: ì´ 16896ê°œ ë¬¸ì¥ â†’ data/merged_train.csv ì €ì¥ë¨\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ê° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "harmful = pd.read_csv(\"data/harmful_train.csv\")\n",
    "normal1 = pd.read_csv(\"data/train_normal_corpus1.csv\")\n",
    "normal2 = pd.read_csv(\"data/train_normal_corpus2.csv\")\n",
    "\n",
    "# ìœ í•´ ë¬¸ì¥ ìˆ˜\n",
    "n_harmful = len(harmful)\n",
    "\n",
    "# ì •ìƒì€ ë°˜ë°˜ ìƒ˜í”Œë§ (ì´í•©ì´ ìœ í•´ì™€ ë™ì¼í•˜ê²Œ)\n",
    "n_each = n_harmful // 2\n",
    "normal1_sampled = normal1.sample(n=n_each, random_state=42)\n",
    "normal2_sampled = normal2.sample(n=n_harmful - n_each, random_state=42)  # odd num ëŒ€ì‘\n",
    "\n",
    "# ë³‘í•©\n",
    "merged = pd.concat([harmful, normal1_sampled, normal2_sampled], ignore_index=True)\n",
    "\n",
    "# ì…”í”Œ (ëª¨ë¸ í•™ìŠµ ì•ˆì •í™”ë¥¼ ìœ„í•´)\n",
    "merged = merged.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# ì €ì¥\n",
    "merged.to_csv(\"data/merged_train.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… ë³‘í•© ì™„ë£Œ: ì´ {len(merged)}ê°œ ë¬¸ì¥ â†’ data/merged_train.csv ì €ì¥ë¨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f24a23ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\MSI\\.cache\\huggingface\\hub\\models--monologg--kobert. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16896/16896 [14:58<00:00, 18.80it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2112/2112 [01:52<00:00, 18.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ë²”ì£„       0.57      0.46      0.51       192\n",
      "      ë¹„ë‚œí˜ì˜¤ì°¨ë³„       0.57      0.74      0.65       320\n",
      "          ì„ ì •       0.43      0.45      0.44        96\n",
      "       ìŠ¤íŒ¸ë°ê´‘ê³        0.52      0.40      0.45        96\n",
      "          ìš•ì„¤       0.14      0.03      0.05        64\n",
      "          ì •ìƒ       0.99      1.00      0.99      1056\n",
      "          í­ë ¥       0.54      0.58      0.56       224\n",
      "     í—ˆìœ„ì •ë³´ë°ë£¨ë¨¸       0.32      0.23      0.27        64\n",
      "\n",
      "    accuracy                           0.76      2112\n",
      "   macro avg       0.51      0.49      0.49      2112\n",
      "weighted avg       0.75      0.76      0.75      2112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# âœ… KoBERT ë¡œë“œ\n",
    "MODEL_NAME = \"monologg/kobert\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = BertModel.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# âœ… í…ìŠ¤íŠ¸ â†’ KoBERT ì„ë² ë”© ì¶”ì¶œ\n",
    "def get_embedding(text, max_len=128):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_len, padding=\"max_length\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # [CLS] í† í° ë²¡í„°\n",
    "    return cls_embedding.squeeze().cpu().numpy()\n",
    "\n",
    "# âœ… ì „ì²´ ë²¡í„°í™”\n",
    "def embed_corpus(texts):\n",
    "    return [get_embedding(text) for text in tqdm(texts)]\n",
    "\n",
    "# âœ… ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(r\"C:\\Users\\MSI\\Desktop\\SpamGuard-MLOps\\data\\train\\merged_train.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\MSI\\Desktop\\SpamGuard-MLOps\\data\\test\\merged_test.csv\")\n",
    "\n",
    "# âœ… í´ë˜ìŠ¤ ì¸ì½”ë”©\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_df[\"label\"])\n",
    "y_test = le.transform(test_df[\"label\"])\n",
    "\n",
    "# âœ… ë²¡í„° ì¶”ì¶œ\n",
    "X_train = embed_corpus(train_df[\"text\"])\n",
    "X_test = embed_corpus(test_df[\"text\"])\n",
    "\n",
    "# âœ… ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ (ë¡œì§€ìŠ¤í‹± íšŒê·€)\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# âœ… í‰ê°€\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ebfd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix_and_normalize(text):\n",
    "    import re\n",
    "    text = re.sub(r\"^(ì •ë‹µ|ë‹µë³€|ê·¼ê±° ë¬¸ì¥|ê·¼ê±°)\\s*[:ï¼š]?\\s*\", \"\", text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ff5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_template_tags(text):\n",
    "    tags = {\n",
    "        \"[ì¸ë¬¼]\": \"íŠ¹ì • ì¸ë¬¼\",\n",
    "        \"[ì§ì—…]\": \"íŠ¹ì • ì§ì—…\",\n",
    "        \"[ì¥ì†Œ]\": \"íŠ¹ì • ì¥ì†Œ\",\n",
    "        \"[ê¸°ì—….ê¸°íƒ€]\": \"ê¸°íƒ€ê¸°ì—…\",\n",
    "        \"[ì œí’ˆ]\": \"íŠ¹ì • ì œí’ˆ\",\n",
    "        \"[ì •ë‹¹]\": \"íŠ¹ì • ì •ë‹¹\",\n",
    "        \"[ì¢…êµ]\": \"íŠ¹ì • ì¢…êµ\",\n",
    "        \"[ìŒì‹]\": \"íŠ¹ì • ìŒì‹\",\n",
    "        \"[ê¸°ê´€]\": \"íŠ¹ì • ê¸°ê´€\",\n",
    "        \"[ì‹ ë…]\": \"íŠ¹ì • ì‹ ë…\",\n",
    "        \"[ì´ë¦„]\": \"íŠ¹ì • ì´ë¦„\",\n",
    "        \"[ì§€ì—­]\": \"íŠ¹ì • ì§€ì—­\",\n",
    "    }\n",
    "    for k, v in tags.items():\n",
    "        text = text.replace(k, v)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d11d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "def extract_key_tokens(text):\n",
    "    return [w for w, p in okt.pos(text) if p in ['Noun', 'Verb', 'Adjective']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "229a61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = {'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜'}\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [w for w in tokens if w not in stop_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5817e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_symbols(text):\n",
    "    text = re.sub(r\"([ã…‹ã…ã…œã… ])\\1{2,}\", r\"\\1\\1\", text)\n",
    "    text = text.replace(\"?\", \" <QUESTION>\").replace(\"!\", \" <EXCLAMATION>\")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69a4ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_preprocess(text):\n",
    "    text = remove_prefix_and_normalize(text)\n",
    "    text = replace_template_tags(text)\n",
    "    text = normalize_symbols(text)\n",
    "    tokens = extract_key_tokens(text)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5627b241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16896/16896 [13:05<00:00, 21.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2112/2112 [01:38<00:00, 21.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# âœ… GPU ì„¸íŒ…\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# âœ… KoBERT ëª¨ë¸ ë¡œë”©\n",
    "MODEL_NAME = \"monologg/kobert\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = BertModel.from_pretrained(MODEL_NAME)\n",
    "model.eval().to(device)\n",
    "\n",
    "# âœ… í…ìŠ¤íŠ¸ â†’ KoBERT ì„ë² ë”© í•¨ìˆ˜\n",
    "def get_embedding(text, max_len=128):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_len, padding=\"max_length\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # [CLS] ì„ë² ë”©\n",
    "    return cls_embedding.squeeze().cpu().numpy()\n",
    "\n",
    "# âœ… ì „ì²´ ë²¡í„°í™” í•¨ìˆ˜\n",
    "def embed_corpus(texts):\n",
    "    return [get_embedding(text) for text in tqdm(texts)]\n",
    "\n",
    "# âœ… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "train_df = pd.read_csv(r\"C:\\Users\\MSI\\Desktop\\SpamGuard-MLOps\\data\\train\\merged_train.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\MSI\\Desktop\\SpamGuard-MLOps\\data\\test\\merged_test.csv\")\n",
    "\n",
    "# âœ… ì „ì²˜ë¦¬ ì ìš©\n",
    "train_df[\"text\"] = train_df[\"text\"].map(full_preprocess)\n",
    "test_df[\"text\"] = test_df[\"text\"].map(full_preprocess)\n",
    "\n",
    "# âœ… í´ë˜ìŠ¤ ì¸ì½”ë”©\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_df[\"label\"])\n",
    "y_test = le.transform(test_df[\"label\"])\n",
    "\n",
    "# âœ… ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ë¡œ ì„ë² ë”© ìƒì„±\n",
    "X_train = embed_corpus(train_df[\"text\"])\n",
    "X_test = embed_corpus(test_df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "143e4b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ëª¨ë¸: LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ë²”ì£„       0.62      0.47      0.54       192\n",
      "      ë¹„ë‚œí˜ì˜¤ì°¨ë³„       0.59      0.67      0.63       320\n",
      "          ì„ ì •       0.55      0.61      0.58        96\n",
      "       ìŠ¤íŒ¸ë°ê´‘ê³        0.60      0.56      0.58        96\n",
      "          ìš•ì„¤       0.33      0.20      0.25        64\n",
      "          ì •ìƒ       0.92      0.95      0.93      1056\n",
      "          í­ë ¥       0.51      0.54      0.52       224\n",
      "     í—ˆìœ„ì •ë³´ë°ë£¨ë¨¸       0.69      0.45      0.55        64\n",
      "\n",
      "    accuracy                           0.75      2112\n",
      "   macro avg       0.60      0.56      0.57      2112\n",
      "weighted avg       0.74      0.75      0.74      2112\n",
      "\n",
      "\n",
      "ğŸš€ ëª¨ë¸: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ë²”ì£„       0.46      0.24      0.32       192\n",
      "      ë¹„ë‚œí˜ì˜¤ì°¨ë³„       0.43      0.47      0.45       320\n",
      "          ì„ ì •       0.76      0.23      0.35        96\n",
      "       ìŠ¤íŒ¸ë°ê´‘ê³        0.67      0.08      0.15        96\n",
      "          ìš•ì„¤       0.00      0.00      0.00        64\n",
      "          ì •ìƒ       0.71      0.95      0.82      1056\n",
      "          í­ë ¥       0.39      0.36      0.37       224\n",
      "     í—ˆìœ„ì •ë³´ë°ë£¨ë¨¸       0.83      0.08      0.14        64\n",
      "\n",
      "    accuracy                           0.62      2112\n",
      "   macro avg       0.53      0.30      0.32      2112\n",
      "weighted avg       0.59      0.62      0.57      2112\n",
      "\n",
      "\n",
      "ğŸš€ ëª¨ë¸: XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:16:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ë²”ì£„       0.57      0.42      0.48       192\n",
      "      ë¹„ë‚œí˜ì˜¤ì°¨ë³„       0.53      0.65      0.58       320\n",
      "          ì„ ì •       0.59      0.43      0.49        96\n",
      "       ìŠ¤íŒ¸ë°ê´‘ê³        0.52      0.34      0.41        96\n",
      "          ìš•ì„¤       0.31      0.06      0.10        64\n",
      "          ì •ìƒ       0.88      0.94      0.91      1056\n",
      "          í­ë ¥       0.42      0.53      0.47       224\n",
      "     í—ˆìœ„ì •ë³´ë°ë£¨ë¨¸       0.90      0.28      0.43        64\n",
      "\n",
      "    accuracy                           0.71      2112\n",
      "   macro avg       0.59      0.46      0.49      2112\n",
      "weighted avg       0.70      0.71      0.70      2112\n",
      "\n",
      "\n",
      "ğŸš€ ëª¨ë¸: SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ë²”ì£„       0.56      0.52      0.54       192\n",
      "      ë¹„ë‚œí˜ì˜¤ì°¨ë³„       0.59      0.68      0.63       320\n",
      "          ì„ ì •       0.57      0.62      0.59        96\n",
      "       ìŠ¤íŒ¸ë°ê´‘ê³        0.59      0.55      0.57        96\n",
      "          ìš•ì„¤       0.30      0.22      0.25        64\n",
      "          ì •ìƒ       0.93      0.93      0.93      1056\n",
      "          í­ë ¥       0.53      0.52      0.52       224\n",
      "     í—ˆìœ„ì •ë³´ë°ë£¨ë¨¸       0.67      0.41      0.50        64\n",
      "\n",
      "    accuracy                           0.75      2112\n",
      "   macro avg       0.59      0.56      0.57      2112\n",
      "weighted avg       0.74      0.75      0.74      2112\n",
      "\n",
      "\n",
      "ğŸš€ ëª¨ë¸: KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] ì§€ì •ëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ë²”ì£„       0.37      0.56      0.44       192\n",
      "      ë¹„ë‚œí˜ì˜¤ì°¨ë³„       0.42      0.57      0.48       320\n",
      "          ì„ ì •       0.39      0.44      0.41        96\n",
      "       ìŠ¤íŒ¸ë°ê´‘ê³        0.29      0.24      0.26        96\n",
      "          ìš•ì„¤       0.07      0.05      0.06        64\n",
      "          ì •ìƒ       0.97      0.79      0.87      1056\n",
      "          í­ë ¥       0.36      0.38      0.37       224\n",
      "     í—ˆìœ„ì •ë³´ë°ë£¨ë¨¸       0.52      0.39      0.45        64\n",
      "\n",
      "    accuracy                           0.62      2112\n",
      "   macro avg       0.42      0.43      0.42      2112\n",
      "weighted avg       0.67      0.62      0.63      2112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ëª¨ë¸ ëª©ë¡\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    \"SVC\": SVC(kernel='linear', probability=True),  # í° ë°ì´í„°ì…‹ì¼ ê²½ìš° ëŠë¦¼\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# í›ˆë ¨ + í‰ê°€\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nğŸš€ ëª¨ë¸: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f57e6ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16896/16896 [00:02<00:00, 7872.55 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2112/2112 [00:00<00:00, 7172.64 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(8002, 768, padding_idx=1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "\n",
    "\n",
    "# âœ… 1. ë°ì´í„° ë¡œë“œ & ì „ì²˜ë¦¬ ì ìš©\n",
    "train_df = pd.read_csv(r\"C:\\Users\\MSI\\Desktop\\SpamGuard-MLOps\\data\\train\\merged_train.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\MSI\\Desktop\\SpamGuard-MLOps\\data\\test\\merged_test.csv\")\n",
    "\n",
    "# ì „ì²˜ë¦¬ í•¨ìˆ˜ ì ìš© (full_preprocessëŠ” ë„¤ê°€ ë§Œë“  í•¨ìˆ˜ ê·¸ëŒ€ë¡œ)\n",
    "train_df[\"text\"] = train_df[\"text\"].map(full_preprocess)\n",
    "test_df[\"text\"] = test_df[\"text\"].map(full_preprocess)\n",
    "\n",
    "# âœ… 2. Label Encoding\n",
    "le = LabelEncoder()\n",
    "train_df[\"label\"] = le.fit_transform(train_df[\"label\"]).astype(\"int64\")\n",
    "test_df [\"label\"] = le.transform(test_df [\"label\"]).astype(\"int64\")\n",
    "num_labels = len(le.classes_)\n",
    "\n",
    "# âœ… 3. Huggingface Dataset ë³€í™˜\n",
    "train_dataset = Dataset.from_pandas(train_df[[\"text\", \"label\"]])\n",
    "test_dataset = Dataset.from_pandas(test_df[[\"text\", \"label\"]])\n",
    "\n",
    "# âœ… 4. Tokenizer ë¡œë”© ë° í† í¬ë‚˜ì´ì§•\n",
    "MODEL_NAME = \"monologg/kobert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False, trust_remote_code=True)\n",
    "\n",
    "if tokenizer.pad_token is None:                     # KoBERTì—” padê°€ ì—†ìŒ\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "def tok_fn(batch):\n",
    "    return tokenizer(batch[\"text\"],\n",
    "               truncation=True,\n",
    "               padding=\"max_length\",\n",
    "               max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tok_fn, batched=True, remove_columns=[\"text\"])\n",
    "test_dataset  = test_dataset .map(tok_fn, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "\n",
    "# âœ… 5. ëª¨ë¸ ë¡œë”© (num_labels ì¤‘ìš”!)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "model.resize_token_embeddings(len(tokenizer))       # pad í† í° ì¶”ê°€ëìœ¼ë¯€ë¡œ í•„ìˆ˜\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89c88a82",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m      6\u001b[39m training_args = TrainingArguments(\n\u001b[32m      7\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./results\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     eval_strategy=\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     report_to=\u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# wandb ì—°ë™ X\u001b[39;00m\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# âœ… 7. Trainer êµ¬ì„±\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m trainer = \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# âœ… 8. í•™ìŠµ ì‹œì‘\u001b[39;00m\n\u001b[32m     30\u001b[39m trainer.train()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:455\u001b[39m, in \u001b[36mTrainer.__init__\u001b[39m\u001b[34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28mself\u001b[39m.compute_loss_func = compute_loss_func\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# Seed must be set before instantiating the model when using model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m enable_full_determinism(\u001b[38;5;28mself\u001b[39m.args.seed) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.full_determinism \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mset_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28mself\u001b[39m.hp_name = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[38;5;28mself\u001b[39m.deepspeed = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer_utils.py:105\u001b[39m, in \u001b[36mset_seed\u001b[39m\u001b[34m(seed, deterministic)\u001b[39m\n\u001b[32m    103\u001b[39m np.random.seed(seed)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     torch.cuda.manual_seed_all(seed)\n\u001b[32m    107\u001b[39m     \u001b[38;5;66;03m# ^^ safe to call this function even if cuda is not available\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_compile.py:32\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     30\u001b[39m     fn.__dynamo_disable = disable_fn\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    741\u001b[39m prior_skip_guard_eval_unsafe = set_skip_guard_eval_unsafe(\n\u001b[32m    742\u001b[39m     _is_skip_guard_eval_unsafe_stance()\n\u001b[32m    743\u001b[39m )\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    747\u001b[39m     _maybe_set_eval_frame(prior)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\random.py:46\u001b[39m, in \u001b[36mmanual_seed\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcuda\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.cuda._is_in_bad_fork():\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmps\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.mps._is_in_bad_fork():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\random.py:127\u001b[39m, in \u001b[36mmanual_seed_all\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m    124\u001b[39m         default_generator = torch.cuda.default_generators[i]\n\u001b[32m    125\u001b[39m         default_generator.manual_seed(seed)\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:249\u001b[39m, in \u001b[36m_lazy_call\u001b[39m\u001b[34m(callable, **kwargs)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_lazy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m, **kwargs):\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    251\u001b[39m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[32m    252\u001b[39m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[32m    253\u001b[39m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[32m    254\u001b[39m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\random.py:125\u001b[39m, in \u001b[36mmanual_seed_all.<locals>.cb\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[32m    124\u001b[39m     default_generator = torch.cuda.default_generators[i]\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     default_generator.manual_seed(seed)\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  # ì •í™•í•œ ì˜¤ë¥˜ ìœ„ì¹˜ ì¶”ì [1][6]\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)\n",
    "# âœ… 6. TrainingArguments ì„¤ì •\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    report_to=\"none\"  # wandb ì—°ë™ X\n",
    ")\n",
    "\n",
    "# âœ… 7. Trainer êµ¬ì„±\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# âœ… 8. í•™ìŠµ ì‹œì‘\n",
    "trainer.train()\n",
    "\n",
    "# âœ… 9. ì˜ˆì¸¡ ë° í‰ê°€\n",
    "preds = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "y_true = test_df[\"label\"].values\n",
    "\n",
    "print(\"\\nğŸ“Š Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b82a8ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA ì‚¬ìš© ê°€ëŠ¥? True\n",
      "í˜„ì¬ GPU ìˆ˜: 1\n",
      "ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: 0\n",
      "ë””ë°”ì´ìŠ¤ ì´ë¦„: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA ì‚¬ìš© ê°€ëŠ¥?\", torch.cuda.is_available())\n",
    "print(\"í˜„ì¬ GPU ìˆ˜:\", torch.cuda.device_count())\n",
    "print(\"ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤:\", torch.cuda.current_device())\n",
    "print(\"ë””ë°”ì´ìŠ¤ ì´ë¦„:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "58ba6224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train_df label íƒ€ì…: int64\n",
      "âœ… max label: 7\n",
      "âœ… unique label ìˆ˜: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"âœ… train_df label íƒ€ì…:\", train_df[\"label\"].dtype)\n",
    "print(\"âœ… max label:\", train_df[\"label\"].max())\n",
    "print(\"âœ… unique label ìˆ˜:\", train_df[\"label\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c5da2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "0\n",
      "label\n",
      "<class 'int'>    16896\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df[\"label\"].dtype)  # int? float? object? -> intì—¬ì•¼ í•¨\n",
    "print(sorted(train_df[\"label\"].unique()))\n",
    "print(train_df[\"label\"].isnull().sum())\n",
    "print(train_df[\"label\"].map(type).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a02f3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'íŠ¹ì • ì§€ì—­ íŠ¹ì • ì¥ì†Œ ì¡°ì„± ì‚¬ì—… íˆ¬ì ì‹¬ì‚¬ ê³¼ì • ì‚¬ì—… ìŠ¹ì¸ ë‚´ì¤€ ëŒ€ê°€ ë’·ëˆ ì±™ê¸´ ë“¤í†µ ë‚˜ì§€ ì•Šì„ ë°©ë²• ì•Œë ¤ì¤˜', 'label': 6, 'input_ids': [2, 4786, 4329, 4786, 3962, 4177, 2609, 4768, 3065, 1065, 2609, 2957, 1434, 7288, 1633, 5330, 1786, 5866, 4463, 1801, 7636, 1370, 7318, 3163, 2270, 3169, 7303, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'text': 'ì•¼ì™¸ ëˆ„ë“œ ì´¬ì˜ í•˜ê³  ì‹¶ì€ë° ì‚¬ëŒ ë‹¤ë‹ˆì§€ ì•Šê³  ì‚¬ì§„ ì°ê¸° í¸í•  ë§Œ ì¥ì†Œ ì¶”ì²œ í•´ ì£¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆê¹Œ', 'label': 2, 'input_ids': [2, 3210, 1526, 5920, 4518, 4926, 3075, 5850, 2584, 1564, 7318, 3149, 2627, 4400, 5561, 4832, 7836, 1931, 3962, 4559, 4998, 4213, 6738, 2872, 3854, 6700, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])\n",
    "print(test_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cae53664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 5, 3, 5, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[:5][\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7399bae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max id: 8001\n",
      "vocab : 8002\n"
     ]
    }
   ],
   "source": [
    "def max_token_id(dataset):\n",
    "    return max(int(id_) for example in dataset for id_ in example[\"input_ids\"])\n",
    "\n",
    "print(\"max id:\", max_token_id(train_dataset))\n",
    "print(\"vocab :\", model.config.vocab_size)\n",
    "assert max_token_id(train_dataset) < model.config.vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5f99da9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mCUDA_LAUNCH_BLOCKING\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# ê¼­ ë§¨ ìœ„ì—\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m a = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m b = torch.tensor([\u001b[32m1.0\u001b[39m], device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m c = a + b  \u001b[38;5;66;03m# ì˜¤ë¥˜ ë°œìƒ\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # ê¼­ ë§¨ ìœ„ì—\n",
    "import torch\n",
    "\n",
    "a = torch.tensor([1.0], device=\"cuda\")\n",
    "b = torch.tensor([1.0], device=\"cpu\")\n",
    "c = a + b  # ì˜¤ë¥˜ ë°œìƒ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ec37e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
